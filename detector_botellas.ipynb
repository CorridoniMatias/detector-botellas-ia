{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "detector_botellas.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OvlxnFIsNyT"
      },
      "source": [
        "# RNA Multi-Perceptrón Backpropagation para procesar las imágenes e identificar si es una botella normal, un bidón retornable o un bidón plástico."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGdqrNAvsWiF"
      },
      "source": [
        "## Cargar librerías:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTPfrarAwacS",
        "outputId": "13cdeace-643f-47eb-d28d-8dc440183b5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "!sudo apt install subversion"
      ],
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "subversion is already the newest version (1.9.7-4ubuntu1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 21 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "id": "gcVLfyLKsaCj",
        "outputId": "b5401c8b-e9ee-4776-ebb4-28dc4ca78289",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import keras\n",
        "from keras.layers import Input, Dense, Flatten\n",
        "from keras.models import Model\n",
        "from keras.utils import plot_model\n",
        "\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import sys\n",
        "import shutil\n",
        "\n",
        "IS_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if IS_COLAB:\n",
        "  print('Running on Google Colab')\n",
        "\n",
        "print(\"Librerías cargadas\")"
      ],
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running on Google Colab\n",
            "Librerías cargadas\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXate9UMmhDA"
      },
      "source": [
        "## Definir los parámetros:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JT7y1jKmrD9"
      },
      "source": [
        "# tamaño de las imágenes\n",
        "IMAGE_HEIGHT = 64\n",
        "IMAGE_WIDTH = 64\n",
        "IMAGE_SHAPE = (IMAGE_HEIGHT, IMAGE_WIDTH, 1)\n",
        "\n",
        "# define tamaño de datos de entrada \n",
        "num_inputs = IMAGE_SHAPE[0] * IMAGE_SHAPE[1] * IMAGE_SHAPE[2]\n",
        "\n",
        "\n",
        "# define tamaño de datos de salida (las clases están codificadas en un único número)\n",
        "num_outputs = 1 \n",
        "\n",
        "# cantidad de neuronas ocultas \n",
        "hidden_layers_neuron_counts = [ 3000, 1024, 512 ] \n",
        "\n",
        "\n",
        "# cantidad de iteraciones del entrenamiento\n",
        "epochs_count = 100\n",
        "\n",
        "# print(\"Configuración de RNA MLP Backpropagation definida: [\", num_inputs, hidden_layers_neuron_counts, num_outputs,\" ] \")"
      ],
      "execution_count": 237,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKZ61Lmz0V9I"
      },
      "source": [
        "### Algunas otras burocracias.."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VAApxEZyD-i",
        "outputId": "913bb4d6-48ea-408a-a865-d2b623054777",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "if IS_COLAB:\n",
        "    DATASET_PATH = '/content/datasets'\n",
        "else:\n",
        "    DATASET_PATH = './datasets'\n",
        "\n",
        "IMAGE_CLASSES = ['bidon_plastico', 'botella_normal', 'bidon_retornable']\n",
        "RAW_PATH = os.path.join(DATASET_PATH, 'raw')\n",
        "MINIFIED_PATH = os.path.join(DATASET_PATH, 'minified')\n",
        "\n",
        "if not os.path.exists(DATASET_PATH):\n",
        "    os.makedirs(DATASET_PATH)\n",
        "\n",
        "\n",
        "print('Done!')"
      ],
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Rm33ZPNnBpE"
      },
      "source": [
        "## Descarga las imagenes de drive, si se está corriendo en colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hejXNbHD0BCj",
        "outputId": "6b269410-68da-472d-e654-7c40611b3e4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "! cd datasets && rm -rf raw && svn checkout https://github.com/CorridoniMatias/detector-botellas-ia/trunk/datasets/raw"
      ],
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A    raw/bidon_plastico\n",
            "A    raw/bidon_plastico/0001.jpg\n",
            "A    raw/bidon_plastico/0002.jpg\n",
            "A    raw/bidon_plastico/0003.jpg\n",
            "A    raw/bidon_plastico/0004.jpg\n",
            "A    raw/bidon_plastico/0005.jpg\n",
            "A    raw/bidon_plastico/0006.jpg\n",
            "A    raw/bidon_plastico/0007.jpg\n",
            "A    raw/bidon_plastico/0008.jpg\n",
            "A    raw/bidon_plastico/0009.jpg\n",
            "A    raw/bidon_plastico/0010.jpg\n",
            "A    raw/bidon_plastico/0011.jpg\n",
            "A    raw/bidon_plastico/0012.jpg\n",
            "A    raw/bidon_plastico/0013.jpg\n",
            "A    raw/bidon_plastico/0014.jpg\n",
            "A    raw/bidon_plastico/0015.jpg\n",
            "A    raw/bidon_plastico/0016.jpg\n",
            "A    raw/bidon_plastico/0017.jpg\n",
            "A    raw/bidon_plastico/0018.jpg\n",
            "A    raw/bidon_plastico/0019.jpg\n",
            "A    raw/bidon_plastico/0020.jpg\n",
            "A    raw/bidon_plastico/0021.jpg\n",
            "A    raw/bidon_plastico/0022.jpg\n",
            "A    raw/bidon_plastico/0023.jpg\n",
            "A    raw/bidon_plastico/0024.jpg\n",
            "A    raw/bidon_plastico/0025.jpg\n",
            "A    raw/bidon_plastico/0026.jpg\n",
            "A    raw/bidon_plastico/0027.jpg\n",
            "A    raw/bidon_plastico/0028.jpg\n",
            "A    raw/bidon_plastico/0029.jpg\n",
            "A    raw/bidon_plastico/0030.jpg\n",
            "A    raw/bidon_plastico/0031.jpg\n",
            "A    raw/bidon_plastico/0032.jpg\n",
            "A    raw/bidon_plastico/0033.jpg\n",
            "A    raw/bidon_plastico/0034.jpg\n",
            "A    raw/bidon_plastico/0035.jpg\n",
            "A    raw/bidon_plastico/0036.jpg\n",
            "A    raw/bidon_plastico/0037.jpg\n",
            "A    raw/bidon_plastico/0038.jpg\n",
            "A    raw/bidon_plastico/0039.jpg\n",
            "A    raw/bidon_plastico/0040.jpg\n",
            "A    raw/bidon_retornable\n",
            "A    raw/bidon_retornable/0001.jpg\n",
            "A    raw/bidon_retornable/0002.jpg\n",
            "A    raw/bidon_retornable/0003.jpg\n",
            "A    raw/bidon_retornable/0004.jpg\n",
            "A    raw/bidon_retornable/0005.jpg\n",
            "A    raw/bidon_retornable/0006.jpg\n",
            "A    raw/bidon_retornable/0007.jpg\n",
            "A    raw/bidon_retornable/0008.jpg\n",
            "A    raw/bidon_retornable/0009.jpg\n",
            "A    raw/bidon_retornable/0010.jpg\n",
            "A    raw/bidon_retornable/0011.jpg\n",
            "A    raw/bidon_retornable/0012.jpg\n",
            "A    raw/bidon_retornable/0013.jpg\n",
            "A    raw/bidon_retornable/0014.jpg\n",
            "A    raw/bidon_retornable/0015.jpg\n",
            "A    raw/bidon_retornable/0016.jpg\n",
            "A    raw/bidon_retornable/0017.jpg\n",
            "A    raw/bidon_retornable/0018.jpg\n",
            "A    raw/bidon_retornable/0019.jpg\n",
            "A    raw/bidon_retornable/0020.png\n",
            "A    raw/bidon_retornable/0021.jpg\n",
            "A    raw/bidon_retornable/0022.jpg\n",
            "A    raw/bidon_retornable/0023.jpg\n",
            "A    raw/bidon_retornable/0024.jpeg\n",
            "A    raw/bidon_retornable/0025.jpg\n",
            "A    raw/bidon_retornable/0027.jpg\n",
            "A    raw/bidon_retornable/0028.jpg\n",
            "A    raw/bidon_retornable/0031.jpg\n",
            "A    raw/bidon_retornable/0032.jpg\n",
            "A    raw/bidon_retornable/0033.jpeg\n",
            "A    raw/bidon_retornable/0035.jpg\n",
            "A    raw/bidon_retornable/0036.jpg\n",
            "A    raw/bidon_retornable/0037.jpg\n",
            "A    raw/bidon_retornable/0038.jpg\n",
            "A    raw/bidon_retornable/0039.png\n",
            "A    raw/bidon_retornable/0040.jpg\n",
            "A    raw/bidon_retornable/0041.jpg\n",
            "A    raw/bidon_retornable/0042.jpg\n",
            "A    raw/bidon_retornable/0043.jpg\n",
            "A    raw/bidon_retornable/0045.jpg\n",
            "A    raw/bidon_retornable/0046.jpg\n",
            "A    raw/bidon_retornable/0047.jpg\n",
            "A    raw/botella_normal\n",
            "A    raw/botella_normal/0001.jpg\n",
            "A    raw/botella_normal/0002.jpg\n",
            "A    raw/botella_normal/0003.jpg\n",
            "A    raw/botella_normal/0004.jpg\n",
            "A    raw/botella_normal/0005.jpg\n",
            "A    raw/botella_normal/0006.jpg\n",
            "A    raw/botella_normal/0007.jpg\n",
            "A    raw/botella_normal/0008.jpg\n",
            "A    raw/botella_normal/0009.jpg\n",
            "A    raw/botella_normal/0010.jpg\n",
            "A    raw/botella_normal/0011.jpg\n",
            "A    raw/botella_normal/0012.jpg\n",
            "A    raw/botella_normal/0013.jpg\n",
            "A    raw/botella_normal/0014.png\n",
            "A    raw/botella_normal/0015.jpg\n",
            "A    raw/botella_normal/0016.jpg\n",
            "A    raw/botella_normal/0017.jpg\n",
            "A    raw/botella_normal/0018.jpg\n",
            "A    raw/botella_normal/0019.jpg\n",
            "A    raw/botella_normal/0020.jpg\n",
            "A    raw/botella_normal/0021.jpg\n",
            "A    raw/botella_normal/0022.jpg\n",
            "A    raw/botella_normal/0023.jpg\n",
            "A    raw/botella_normal/0024.jpg\n",
            "A    raw/botella_normal/0025.jpg\n",
            "A    raw/botella_normal/0026.jpg\n",
            "A    raw/botella_normal/0027.jpg\n",
            "A    raw/botella_normal/0028.jpg\n",
            "A    raw/botella_normal/0029.jpg\n",
            "A    raw/botella_normal/0030.jpg\n",
            "A    raw/botella_normal/0031.jpg\n",
            "A    raw/botella_normal/0032.jpg\n",
            "A    raw/botella_normal/0033.jpg\n",
            "A    raw/botella_normal/0034.jpg\n",
            "A    raw/botella_normal/0035.jpg\n",
            "A    raw/botella_normal/0036.jpg\n",
            "A    raw/botella_normal/0037.jpg\n",
            "A    raw/botella_normal/0038.jpg\n",
            "A    raw/botella_normal/0039.jpg\n",
            "Checked out revision 42.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yszX6OwHwXAx"
      },
      "source": [
        "## Preprocesamiento de imágenes\n",
        "Las imágenes se achican a un tamaño de 64x64 y se convierten a escala de grises."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5-oYK0RwXAy",
        "outputId": "48932c71-09b6-4895-cf92-615d593c7065",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def minimized_image(image):\n",
        "    return image.convert('L').resize((IMAGE_HEIGHT, IMAGE_WIDTH), Image.ANTIALIAS)\n",
        "\n",
        "def minify_image_from_class(from_directory, to_directory):\n",
        "    for root, dirs, files in os.walk(from_directory):\n",
        "        for image_name in files:\n",
        "            image_path = os.path.join(root, image_name)\n",
        "            print(image_path)\n",
        "            image = Image.open(image_path)\n",
        "            image = minimized_image(image)\n",
        "            image.save(os.path.join(to_directory, image_name))\n",
        "\n",
        "for image_class in IMAGE_CLASSES:\n",
        "    input_dir = os.path.join(RAW_PATH, image_class)\n",
        "    output_dir = os.path.join(MINIFIED_PATH, image_class)\n",
        "\n",
        "    if os.path.exists(output_dir):\n",
        "      shutil.rmtree(output_dir)\n",
        "    \n",
        "    os.makedirs(output_dir)\n",
        "    minify_image_from_class(input_dir, output_dir)\n",
        "\n",
        "print('Done')\n"
      ],
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/datasets/raw/bidon_plastico/0032.jpg\n",
            "/content/datasets/raw/bidon_plastico/0036.jpg\n",
            "/content/datasets/raw/bidon_plastico/0011.jpg\n",
            "/content/datasets/raw/bidon_plastico/0035.jpg\n",
            "/content/datasets/raw/bidon_plastico/0040.jpg\n",
            "/content/datasets/raw/bidon_plastico/0005.jpg\n",
            "/content/datasets/raw/bidon_plastico/0019.jpg\n",
            "/content/datasets/raw/bidon_plastico/0007.jpg\n",
            "/content/datasets/raw/bidon_plastico/0039.jpg\n",
            "/content/datasets/raw/bidon_plastico/0001.jpg\n",
            "/content/datasets/raw/bidon_plastico/0014.jpg\n",
            "/content/datasets/raw/bidon_plastico/0028.jpg\n",
            "/content/datasets/raw/bidon_plastico/0018.jpg\n",
            "/content/datasets/raw/bidon_plastico/0037.jpg\n",
            "/content/datasets/raw/bidon_plastico/0029.jpg\n",
            "/content/datasets/raw/bidon_plastico/0004.jpg\n",
            "/content/datasets/raw/bidon_plastico/0024.jpg\n",
            "/content/datasets/raw/bidon_plastico/0010.jpg\n",
            "/content/datasets/raw/bidon_plastico/0038.jpg\n",
            "/content/datasets/raw/bidon_plastico/0008.jpg\n",
            "/content/datasets/raw/bidon_plastico/0021.jpg\n",
            "/content/datasets/raw/bidon_plastico/0034.jpg\n",
            "/content/datasets/raw/bidon_plastico/0025.jpg\n",
            "/content/datasets/raw/bidon_plastico/0012.jpg\n",
            "/content/datasets/raw/bidon_plastico/0020.jpg\n",
            "/content/datasets/raw/bidon_plastico/0017.jpg\n",
            "/content/datasets/raw/bidon_plastico/0023.jpg\n",
            "/content/datasets/raw/bidon_plastico/0027.jpg\n",
            "/content/datasets/raw/bidon_plastico/0006.jpg\n",
            "/content/datasets/raw/bidon_plastico/0030.jpg\n",
            "/content/datasets/raw/bidon_plastico/0009.jpg\n",
            "/content/datasets/raw/bidon_plastico/0002.jpg\n",
            "/content/datasets/raw/bidon_plastico/0031.jpg\n",
            "/content/datasets/raw/bidon_plastico/0013.jpg\n",
            "/content/datasets/raw/bidon_plastico/0015.jpg\n",
            "/content/datasets/raw/bidon_plastico/0033.jpg\n",
            "/content/datasets/raw/bidon_plastico/0003.jpg\n",
            "/content/datasets/raw/bidon_plastico/0026.jpg\n",
            "/content/datasets/raw/bidon_plastico/0022.jpg\n",
            "/content/datasets/raw/bidon_plastico/0016.jpg\n",
            "/content/datasets/raw/botella_normal/0032.jpg\n",
            "/content/datasets/raw/botella_normal/0036.jpg\n",
            "/content/datasets/raw/botella_normal/0011.jpg\n",
            "/content/datasets/raw/botella_normal/0035.jpg\n",
            "/content/datasets/raw/botella_normal/0005.jpg\n",
            "/content/datasets/raw/botella_normal/0019.jpg\n",
            "/content/datasets/raw/botella_normal/0007.jpg\n",
            "/content/datasets/raw/botella_normal/0039.jpg\n",
            "/content/datasets/raw/botella_normal/0001.jpg\n",
            "/content/datasets/raw/botella_normal/0028.jpg\n",
            "/content/datasets/raw/botella_normal/0018.jpg\n",
            "/content/datasets/raw/botella_normal/0037.jpg\n",
            "/content/datasets/raw/botella_normal/0029.jpg\n",
            "/content/datasets/raw/botella_normal/0004.jpg\n",
            "/content/datasets/raw/botella_normal/0024.jpg\n",
            "/content/datasets/raw/botella_normal/0010.jpg\n",
            "/content/datasets/raw/botella_normal/0038.jpg\n",
            "/content/datasets/raw/botella_normal/0008.jpg\n",
            "/content/datasets/raw/botella_normal/0021.jpg\n",
            "/content/datasets/raw/botella_normal/0034.jpg\n",
            "/content/datasets/raw/botella_normal/0025.jpg\n",
            "/content/datasets/raw/botella_normal/0014.png\n",
            "/content/datasets/raw/botella_normal/0012.jpg\n",
            "/content/datasets/raw/botella_normal/0020.jpg\n",
            "/content/datasets/raw/botella_normal/0017.jpg\n",
            "/content/datasets/raw/botella_normal/0023.jpg\n",
            "/content/datasets/raw/botella_normal/0027.jpg\n",
            "/content/datasets/raw/botella_normal/0006.jpg\n",
            "/content/datasets/raw/botella_normal/0030.jpg\n",
            "/content/datasets/raw/botella_normal/0009.jpg\n",
            "/content/datasets/raw/botella_normal/0002.jpg\n",
            "/content/datasets/raw/botella_normal/0031.jpg\n",
            "/content/datasets/raw/botella_normal/0013.jpg\n",
            "/content/datasets/raw/botella_normal/0015.jpg\n",
            "/content/datasets/raw/botella_normal/0033.jpg\n",
            "/content/datasets/raw/botella_normal/0003.jpg\n",
            "/content/datasets/raw/botella_normal/0026.jpg\n",
            "/content/datasets/raw/botella_normal/0022.jpg\n",
            "/content/datasets/raw/botella_normal/0016.jpg\n",
            "/content/datasets/raw/bidon_retornable/0032.jpg\n",
            "/content/datasets/raw/bidon_retornable/0036.jpg\n",
            "/content/datasets/raw/bidon_retornable/0011.jpg\n",
            "/content/datasets/raw/bidon_retornable/0035.jpg\n",
            "/content/datasets/raw/bidon_retornable/0040.jpg\n",
            "/content/datasets/raw/bidon_retornable/0005.jpg\n",
            "/content/datasets/raw/bidon_retornable/0019.jpg\n",
            "/content/datasets/raw/bidon_retornable/0007.jpg\n",
            "/content/datasets/raw/bidon_retornable/0001.jpg\n",
            "/content/datasets/raw/bidon_retornable/0020.png\n",
            "/content/datasets/raw/bidon_retornable/0014.jpg\n",
            "/content/datasets/raw/bidon_retornable/0028.jpg\n",
            "/content/datasets/raw/bidon_retornable/0018.jpg\n",
            "/content/datasets/raw/bidon_retornable/0037.jpg\n",
            "/content/datasets/raw/bidon_retornable/0039.png\n",
            "/content/datasets/raw/bidon_retornable/0004.jpg\n",
            "/content/datasets/raw/bidon_retornable/0010.jpg\n",
            "/content/datasets/raw/bidon_retornable/0024.jpeg\n",
            "/content/datasets/raw/bidon_retornable/0033.jpeg\n",
            "/content/datasets/raw/bidon_retornable/0042.jpg\n",
            "/content/datasets/raw/bidon_retornable/0038.jpg\n",
            "/content/datasets/raw/bidon_retornable/0008.jpg\n",
            "/content/datasets/raw/bidon_retornable/0021.jpg\n",
            "/content/datasets/raw/bidon_retornable/0047.jpg\n",
            "/content/datasets/raw/bidon_retornable/0025.jpg\n",
            "/content/datasets/raw/bidon_retornable/0043.jpg\n",
            "/content/datasets/raw/bidon_retornable/0012.jpg\n",
            "/content/datasets/raw/bidon_retornable/0017.jpg\n",
            "/content/datasets/raw/bidon_retornable/0041.jpg\n",
            "/content/datasets/raw/bidon_retornable/0023.jpg\n",
            "/content/datasets/raw/bidon_retornable/0046.jpg\n",
            "/content/datasets/raw/bidon_retornable/0027.jpg\n",
            "/content/datasets/raw/bidon_retornable/0006.jpg\n",
            "/content/datasets/raw/bidon_retornable/0045.jpg\n",
            "/content/datasets/raw/bidon_retornable/0009.jpg\n",
            "/content/datasets/raw/bidon_retornable/0002.jpg\n",
            "/content/datasets/raw/bidon_retornable/0031.jpg\n",
            "/content/datasets/raw/bidon_retornable/0013.jpg\n",
            "/content/datasets/raw/bidon_retornable/0015.jpg\n",
            "/content/datasets/raw/bidon_retornable/0003.jpg\n",
            "/content/datasets/raw/bidon_retornable/0022.jpg\n",
            "/content/datasets/raw/bidon_retornable/0016.jpg\n",
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3oXm4CDwXA2",
        "outputId": "a0df4ee2-9f4e-4e23-ea2f-d6f42737f85d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "\n",
        "\n",
        "import math\n",
        "import re\n",
        "import sys\n",
        "import shutil\n",
        "\n",
        "DISTRIBUTED_PATH = os.path.join(DATASET_PATH, 'distributed')\n",
        "#Train and Test Set Variables\n",
        "train_val_test_ratio = (.5,.25,.25) # 50/25/25 Data Split\n",
        "test_folder = os.path.join(DISTRIBUTED_PATH, 'test')\n",
        "train_folder = os.path.join(DISTRIBUTED_PATH, 'train')\n",
        "val_folder = os.path.join(DISTRIBUTED_PATH, 'val')\n",
        "\n",
        "#Remove Existing Folders if they exist\n",
        "for folder in [test_folder, train_folder, val_folder]:\n",
        "    if os.path.exists(folder) and os.path.isdir(folder):\n",
        "        shutil.rmtree(folder)\n",
        "\n",
        "#Remake Category Folders in both Train and Test Folders\n",
        "for category in IMAGE_CLASSES:\n",
        "    os.makedirs(os.path.join(test_folder, category))\n",
        "    os.makedirs(os.path.join(train_folder, category))\n",
        "    os.makedirs(os.path.join(val_folder, category))\n",
        "\n",
        "#Split Data by Train Ratio and copy files to correct directory\n",
        "for idx, category in enumerate(IMAGE_CLASSES):\n",
        "    file_list = os.listdir(os.path.join(MINIFIED_PATH, category))\n",
        "    \n",
        "    train_ratio = math.floor(len(file_list) * train_val_test_ratio[0])\n",
        "    val_ratio = math.floor(len(file_list) * train_val_test_ratio[1])\n",
        "    train_list = file_list[:train_ratio]\n",
        "    val_list = file_list[train_ratio:train_ratio + val_ratio]\n",
        "    test_list = file_list[train_ratio + val_ratio:]\n",
        "    \n",
        "    for i, file in enumerate(train_list):\n",
        "        shutil.copy(os.path.join(MINIFIED_PATH, category, file), os.path.join(train_folder, category, file))\n",
        "    sys.stdout.write('Moving %s train images to category folder %s' % (len(train_list), category))  \n",
        "    sys.stdout.write('\\n')\n",
        "    for i, file in enumerate(val_list):\n",
        "        shutil.copy(os.path.join(MINIFIED_PATH, category, file), os.path.join(val_folder, category, file))\n",
        "    sys.stdout.write('Moving %s validation images to category folder %s' % (len(val_list), category))                   \n",
        "    sys.stdout.write('\\n')\n",
        "    for i, file in enumerate(test_list):\n",
        "        shutil.copy(os.path.join(MINIFIED_PATH, category, file), os.path.join(test_folder, category, file))\n",
        "    sys.stdout.write('Moving %s test images to category folder %s' % (len(test_list), category))\n",
        "    sys.stdout.write('\\n\\n')\n",
        "    \n",
        "print(\"Done.\")  "
      ],
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Moving 20 train images to category folder bidon_plastico\n",
            "Moving 10 validation images to category folder bidon_plastico\n",
            "Moving 10 test images to category folder bidon_plastico\n",
            "\n",
            "Moving 19 train images to category folder botella_normal\n",
            "Moving 9 validation images to category folder botella_normal\n",
            "Moving 11 test images to category folder botella_normal\n",
            "\n",
            "Moving 21 train images to category folder bidon_retornable\n",
            "Moving 10 validation images to category folder bidon_retornable\n",
            "Moving 11 test images to category folder bidon_retornable\n",
            "\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQEXc9_4wXA6"
      },
      "source": [
        "## Carga de imágenes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RB1DZ7pP6l5G"
      },
      "source": [
        "# Loads images and labels into numpy arrays\n",
        "def load_img_directory(dir_path):\n",
        "  classes = []\n",
        "  images = []\n",
        "  for class_name in os.listdir(dir_path):\n",
        "    for image_name in os.listdir(os.path.join(dir_path, class_name)):          \n",
        "          image = Image.open(os.path.join(dir_path, class_name, image_name))\n",
        "          images.append(np.array(image))\n",
        "          classes.append(class_name)\n",
        "  return (images, classes)"
      ],
      "execution_count": 242,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYz8mV4SnJ4O",
        "outputId": "4efc1c7a-9707-4b0f-f7d6-0ab5126271dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "# cargar las imágenes\n",
        "\n",
        "(x_train, y_train) = load_img_directory(train_folder)\n",
        "(x_val, y_val) = load_img_directory(val_folder)\n",
        "(x_test, y_test) = load_img_directory(test_folder)\n",
        "\n",
        "print('Dataset de train')\n",
        "print(\"- Clases cargadas: \", len(set(y_train)))\n",
        "print(\"- Imágenes cargadas: \", len(x_train))\n",
        "print('')\n",
        "\n",
        "print('Dataset de validación')\n",
        "print(\"- Clases cargadas validación: \", len(set(y_val)))\n",
        "print(\"- Imágenes cargadas validación: \", len(x_val))\n",
        "print('')\n",
        "\n",
        "print('Dataset de test')\n",
        "print(\"- Clases cargadas test: \", len(set(y_test)))\n",
        "print(\"- Imágenes cargadas test: \", len(x_test))\n",
        "print('')"
      ],
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset de train\n",
            "- Clases cargadas:  3\n",
            "- Imágenes cargadas:  60\n",
            "\n",
            "Dataset de validación\n",
            "- Clases cargadas validación:  3\n",
            "- Imágenes cargadas validación:  29\n",
            "\n",
            "Dataset de test\n",
            "- Clases cargadas test:  3\n",
            "- Imágenes cargadas test:  32\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8-5MO7_wXBC"
      },
      "source": [
        "def show_batch(image_batch, label_batch):\n",
        "  plt.figure(figsize=(10,10))\n",
        "  for n in range(len(label_batch)):\n",
        "      ax = plt.subplot(4,7,n+1)\n",
        "      plt.title(label_batch[n])\n",
        "      plt.imshow(image_batch[n])\n",
        "      plt.gray()\n",
        "      plt.axis('off')"
      ],
      "execution_count": 244,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPPvnkjTnTQN",
        "scrolled": true,
        "outputId": "a50eab60-8930-4f88-8b37-3abd5b479e61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        }
      },
      "source": [
        "# define función auxiliar para mostrar imágenes preparadas\n",
        "def plot_image(imag):\n",
        "  if IMAGE_SHAPE[2]==1:\n",
        "    plt.imshow((imag*255).reshape(IMAGE_SHAPE[0], IMAGE_SHAPE[1]).astype(np.uint8))\n",
        "    plt.gray()\n",
        "  else:\n",
        "    plt.imshow((imag*255).reshape(IMAGE_SHAPE).astype(np.uint8))\n",
        "  plt.axis(\"off\")\n",
        "\n",
        "# define función auxiliar para preparar la lista de imágenes a procesar\n",
        "def process_images_array(images):    \n",
        "  images = np.array(images).astype('float32') / 255.\n",
        "  return images.reshape((len(images), num_inputs))\n",
        "\n",
        "def process_classes_array(classes):\n",
        "  mapped = []\n",
        "  for klass in classes:\n",
        "    mapped.append(IMAGE_CLASSES_MAP[klass])\n",
        "  return np.array(mapped)\n",
        "\n",
        "# define vector auxiliar de datos de entrada para usar en el entrenamiento\n",
        "_x_train = process_images_array(x_train)\n",
        "_x_test = process_images_array(x_test)\n",
        "_x_val = process_images_array(x_val)\n",
        "\n",
        "# define vector auxiliar de datos de salida para usar en el entrenamiento\n",
        "# también usa esta información para determinar la cantida de neuronas de salida\n",
        "print(IMAGE_CLASSES)\n",
        "IMAGE_CLASSES_MAP = dict(zip(IMAGE_CLASSES, range(len(IMAGE_CLASSES))))\n",
        "print(IMAGE_CLASSES_MAP)\n",
        "\n",
        "_y_train = process_classes_array(y_train)\n",
        "_y_test = process_classes_array(y_test)\n",
        "_y_val = process_classes_array(y_val)\n",
        "\n",
        "print(\"x_train (cant ejemplos, datos entrada): \", _x_train.shape)\n",
        "print(\"y_train (cant): \", len(y_train))\n",
        "print(\"\\nImagen reconstruida de \", y_train[0])\n",
        "\n",
        "plot_image(x_train[0])"
      ],
      "execution_count": 245,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['bidon_plastico', 'botella_normal', 'bidon_retornable']\n",
            "{'bidon_plastico': 0, 'botella_normal': 1, 'bidon_retornable': 2}\n",
            "x_train (cant ejemplos, datos entrada):  (60, 4096)\n",
            "y_train (cant):  60\n",
            "\n",
            "Imagen reconstruida de  bidon_plastico\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvooB4Gws7ua"
      },
      "source": [
        "## Definiendo el modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwotOaQwwXBJ"
      },
      "source": [
        "import keras\n",
        "import pydot as pyd\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "keras.utils.vis_utils.pydot = pyd\n",
        "\n",
        "#Visualize Model Helper function\n",
        "def visualize_model(model):\n",
        "  return SVG(model_to_dot(model).create(prog='dot', format='svg'))"
      ],
      "execution_count": 246,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SywyoCrcwXBM",
        "outputId": "e85b7df0-7dd9-4d12-c599-2ad9045c9a73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 932
        }
      },
      "source": [
        "import functools\n",
        "import pydot\n",
        "\n",
        "input_layer = Input(shape=(IMAGE_HEIGHT * IMAGE_WIDTH,))\n",
        "\n",
        "hidden_layers = functools.reduce(   lambda previous_layer, neurons_count: Dense(neurons_count, activation=\"relu\")(previous_layer),\n",
        "                                    hidden_layers_neuron_counts,\n",
        "                                    input_layer)\n",
        "\n",
        "output_layer = Dense(num_outputs, activation=None, name='output')(hidden_layers)\n",
        "\n",
        "model = Model(input_layer, output_layer)\n",
        "model.compile(optimizer='rmsprop', loss='mse', metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "visualize_model(model)"
      ],
      "execution_count": 247,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_27\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_14 (InputLayer)        [(None, 4096)]            0         \n",
            "_________________________________________________________________\n",
            "dense_39 (Dense)             (None, 3000)              12291000  \n",
            "_________________________________________________________________\n",
            "dense_40 (Dense)             (None, 1024)              3073024   \n",
            "_________________________________________________________________\n",
            "dense_41 (Dense)             (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 15,889,337\n",
            "Trainable params: 15,889,337\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"449pt\" viewBox=\"0.00 0.00 148.00 337.00\" width=\"197pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1.3333 1.3333) rotate(0) translate(4 333)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-333 144,-333 144,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140362889681328 -->\n<g class=\"node\" id=\"node1\">\n<title>140362889681328</title>\n<polygon fill=\"none\" points=\"0,-292.5 0,-328.5 140,-328.5 140,-292.5 0,-292.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"70\" y=\"-306.8\">input_14: InputLayer</text>\n</g>\n<!-- 140362892740480 -->\n<g class=\"node\" id=\"node2\">\n<title>140362892740480</title>\n<polygon fill=\"none\" points=\"13,-219.5 13,-255.5 127,-255.5 127,-219.5 13,-219.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"70\" y=\"-233.8\">dense_39: Dense</text>\n</g>\n<!-- 140362889681328&#45;&gt;140362892740480 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140362889681328-&gt;140362892740480</title>\n<path d=\"M70,-292.4551C70,-284.3828 70,-274.6764 70,-265.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"73.5001,-265.5903 70,-255.5904 66.5001,-265.5904 73.5001,-265.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140362887063480 -->\n<g class=\"node\" id=\"node3\">\n<title>140362887063480</title>\n<polygon fill=\"none\" points=\"13,-146.5 13,-182.5 127,-182.5 127,-146.5 13,-146.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"70\" y=\"-160.8\">dense_40: Dense</text>\n</g>\n<!-- 140362892740480&#45;&gt;140362887063480 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140362892740480-&gt;140362887063480</title>\n<path d=\"M70,-219.4551C70,-211.3828 70,-201.6764 70,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"73.5001,-192.5903 70,-182.5904 66.5001,-192.5904 73.5001,-192.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140362492174176 -->\n<g class=\"node\" id=\"node4\">\n<title>140362492174176</title>\n<polygon fill=\"none\" points=\"13,-73.5 13,-109.5 127,-109.5 127,-73.5 13,-73.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"70\" y=\"-87.8\">dense_41: Dense</text>\n</g>\n<!-- 140362887063480&#45;&gt;140362492174176 -->\n<g class=\"edge\" id=\"edge3\">\n<title>140362887063480-&gt;140362492174176</title>\n<path d=\"M70,-146.4551C70,-138.3828 70,-128.6764 70,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"73.5001,-119.5903 70,-109.5904 66.5001,-119.5904 73.5001,-119.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140362889679200 -->\n<g class=\"node\" id=\"node5\">\n<title>140362889679200</title>\n<polygon fill=\"none\" points=\"21.5,-.5 21.5,-36.5 118.5,-36.5 118.5,-.5 21.5,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"70\" y=\"-14.8\">output: Dense</text>\n</g>\n<!-- 140362492174176&#45;&gt;140362889679200 -->\n<g class=\"edge\" id=\"edge4\">\n<title>140362492174176-&gt;140362889679200</title>\n<path d=\"M70,-73.4551C70,-65.3828 70,-55.6764 70,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"73.5001,-46.5903 70,-36.5904 66.5001,-46.5904 73.5001,-46.5903\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 247
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBtXyyXCtjDc"
      },
      "source": [
        "## Entrenar el modelo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21pQvmtCtn-T",
        "outputId": "98d4e560-4592-4eb4-d568-9c2b23644893",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# lleva a cabo el entrenamiento\n",
        "model.fit(_x_train, _y_train, epochs = epochs_count, batch_size = 6, validation_data=(_x_val, _y_val))"
      ],
      "execution_count": 248,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "10/10 [==============================] - 0s 20ms/step - loss: 25718.5645 - accuracy: 0.2833 - val_loss: 3.1076 - val_accuracy: 0.3448\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.1982 - accuracy: 0.3833 - val_loss: 0.6906 - val_accuracy: 0.3103\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.8430 - accuracy: 0.3667 - val_loss: 0.6780 - val_accuracy: 0.3793\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.0964 - accuracy: 0.3667 - val_loss: 0.9689 - val_accuracy: 0.3448\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.0658 - accuracy: 0.4167 - val_loss: 0.8635 - val_accuracy: 0.3103\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.8791 - accuracy: 0.4000 - val_loss: 2.1974 - val_accuracy: 0.3448\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.9140 - accuracy: 0.3333 - val_loss: 0.5333 - val_accuracy: 0.3793\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.3510 - accuracy: 0.3167 - val_loss: 0.5830 - val_accuracy: 0.3448\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.1716 - accuracy: 0.2833 - val_loss: 0.6563 - val_accuracy: 0.3103\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.0260 - accuracy: 0.3833 - val_loss: 0.6482 - val_accuracy: 0.3103\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.2297 - accuracy: 0.2833 - val_loss: 4.0415 - val_accuracy: 0.3103\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.4300 - accuracy: 0.3333 - val_loss: 1.2942 - val_accuracy: 0.3103\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.9459 - accuracy: 0.3500 - val_loss: 2.2052 - val_accuracy: 0.3448\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 2.2778 - accuracy: 0.3167 - val_loss: 4.0232 - val_accuracy: 0.3103\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.9422 - accuracy: 0.3167 - val_loss: 3.6729 - val_accuracy: 0.3103\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.3412 - accuracy: 0.3500 - val_loss: 1.1322 - val_accuracy: 0.3448\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.6392 - accuracy: 0.2833 - val_loss: 0.6834 - val_accuracy: 0.3103\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 1.2020 - accuracy: 0.3667 - val_loss: 0.6324 - val_accuracy: 0.3448\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.7282 - accuracy: 0.3500 - val_loss: 0.5505 - val_accuracy: 0.3448\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.9603 - accuracy: 0.3667 - val_loss: 0.7101 - val_accuracy: 0.5517\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6020 - accuracy: 0.4667 - val_loss: 0.6014 - val_accuracy: 0.5172\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.5298 - accuracy: 0.4167 - val_loss: 0.2940 - val_accuracy: 0.4138\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.4189 - accuracy: 0.4500 - val_loss: 0.3737 - val_accuracy: 0.3448\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.4657 - accuracy: 0.3833 - val_loss: 1.3332 - val_accuracy: 0.3448\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.6172 - accuracy: 0.3667 - val_loss: 0.8281 - val_accuracy: 0.3448\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.5668 - accuracy: 0.3833 - val_loss: 0.4423 - val_accuracy: 0.3793\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2413 - accuracy: 0.4833 - val_loss: 0.1408 - val_accuracy: 0.5172\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3952 - accuracy: 0.4167 - val_loss: 0.5821 - val_accuracy: 0.3448\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3504 - accuracy: 0.4500 - val_loss: 0.2246 - val_accuracy: 0.4828\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3167 - accuracy: 0.4167 - val_loss: 0.3939 - val_accuracy: 0.3793\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3874 - accuracy: 0.4500 - val_loss: 0.1608 - val_accuracy: 0.4483\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2320 - accuracy: 0.4333 - val_loss: 0.7729 - val_accuracy: 0.3448\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3323 - accuracy: 0.4000 - val_loss: 0.2595 - val_accuracy: 0.3793\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3809 - accuracy: 0.4333 - val_loss: 0.1410 - val_accuracy: 0.5172\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2589 - accuracy: 0.4500 - val_loss: 0.4064 - val_accuracy: 0.3448\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2944 - accuracy: 0.4667 - val_loss: 0.2174 - val_accuracy: 0.5862\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2077 - accuracy: 0.5500 - val_loss: 0.7072 - val_accuracy: 0.3448\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2942 - accuracy: 0.4667 - val_loss: 0.2475 - val_accuracy: 0.4828\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2361 - accuracy: 0.4833 - val_loss: 0.1548 - val_accuracy: 0.6552\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2346 - accuracy: 0.4667 - val_loss: 0.1807 - val_accuracy: 0.5172\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2351 - accuracy: 0.4667 - val_loss: 0.2607 - val_accuracy: 0.3793\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.2778 - accuracy: 0.3833 - val_loss: 0.2566 - val_accuracy: 0.4138\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2302 - accuracy: 0.5333 - val_loss: 0.1596 - val_accuracy: 0.4483\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3067 - accuracy: 0.3500 - val_loss: 0.3470 - val_accuracy: 0.3793\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1556 - accuracy: 0.4833 - val_loss: 0.1270 - val_accuracy: 0.5172\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1680 - accuracy: 0.5333 - val_loss: 0.2786 - val_accuracy: 0.3793\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3014 - accuracy: 0.3500 - val_loss: 0.8165 - val_accuracy: 0.3448\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2269 - accuracy: 0.5000 - val_loss: 0.3223 - val_accuracy: 0.3793\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2048 - accuracy: 0.4667 - val_loss: 0.3000 - val_accuracy: 0.4828\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1431 - accuracy: 0.5667 - val_loss: 0.1244 - val_accuracy: 0.6207\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2499 - accuracy: 0.4833 - val_loss: 0.2443 - val_accuracy: 0.4828\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2035 - accuracy: 0.5333 - val_loss: 0.1004 - val_accuracy: 0.5517\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.1725 - accuracy: 0.5667 - val_loss: 0.1226 - val_accuracy: 0.6207\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1214 - accuracy: 0.5667 - val_loss: 0.1066 - val_accuracy: 0.6552\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2079 - accuracy: 0.5333 - val_loss: 0.1887 - val_accuracy: 0.4483\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1665 - accuracy: 0.6000 - val_loss: 0.4919 - val_accuracy: 0.3448\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1671 - accuracy: 0.5000 - val_loss: 0.0873 - val_accuracy: 0.5517\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2414 - accuracy: 0.4833 - val_loss: 0.3621 - val_accuracy: 0.5517\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1097 - accuracy: 0.6167 - val_loss: 0.2412 - val_accuracy: 0.4138\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1981 - accuracy: 0.4833 - val_loss: 0.0910 - val_accuracy: 0.5517\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2039 - accuracy: 0.5333 - val_loss: 0.0744 - val_accuracy: 0.6207\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.1764 - accuracy: 0.5667 - val_loss: 0.2307 - val_accuracy: 0.4828\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0918 - accuracy: 0.5833 - val_loss: 0.0942 - val_accuracy: 0.5172\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1935 - accuracy: 0.5667 - val_loss: 0.0947 - val_accuracy: 0.5172\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0239 - accuracy: 0.6500 - val_loss: 0.0663 - val_accuracy: 0.6207\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1418 - accuracy: 0.5833 - val_loss: 0.0733 - val_accuracy: 0.5517\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2110 - accuracy: 0.5000 - val_loss: 0.5018 - val_accuracy: 0.3448\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2021 - accuracy: 0.5667 - val_loss: 0.0649 - val_accuracy: 0.6207\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0773 - accuracy: 0.6500 - val_loss: 0.0595 - val_accuracy: 0.5517\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0487 - accuracy: 0.6333 - val_loss: 1.0538 - val_accuracy: 0.3448\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3907 - accuracy: 0.4167 - val_loss: 0.2756 - val_accuracy: 0.5517\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0565 - accuracy: 0.6500 - val_loss: 0.5357 - val_accuracy: 0.3448\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1843 - accuracy: 0.5667 - val_loss: 0.1143 - val_accuracy: 0.5172\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1190 - accuracy: 0.5500 - val_loss: 0.0765 - val_accuracy: 0.6552\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2669 - accuracy: 0.5333 - val_loss: 0.0693 - val_accuracy: 0.5517\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0214 - accuracy: 0.6500 - val_loss: 0.0526 - val_accuracy: 0.6552\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1407 - accuracy: 0.6167 - val_loss: 0.1036 - val_accuracy: 0.5172\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1700 - accuracy: 0.5833 - val_loss: 0.4239 - val_accuracy: 0.3793\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0556 - accuracy: 0.6167 - val_loss: 0.0548 - val_accuracy: 0.6552\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1551 - accuracy: 0.5500 - val_loss: 0.0564 - val_accuracy: 0.6207\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0726 - accuracy: 0.6333 - val_loss: 0.4839 - val_accuracy: 0.3448\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2579 - accuracy: 0.5333 - val_loss: 0.1129 - val_accuracy: 0.5517\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0254 - accuracy: 0.6500 - val_loss: 0.0786 - val_accuracy: 0.5172\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2409 - accuracy: 0.4500 - val_loss: 0.1419 - val_accuracy: 0.6207\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0599 - accuracy: 0.6333 - val_loss: 0.4063 - val_accuracy: 0.3793\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2065 - accuracy: 0.4833 - val_loss: 0.1666 - val_accuracy: 0.5172\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0747 - accuracy: 0.6167 - val_loss: 0.0864 - val_accuracy: 0.5172\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1168 - accuracy: 0.6000 - val_loss: 0.1024 - val_accuracy: 0.5172\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0644 - accuracy: 0.6167 - val_loss: 0.0532 - val_accuracy: 0.6207\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3074 - accuracy: 0.4500 - val_loss: 0.1094 - val_accuracy: 0.6552\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - 0s 11ms/step - loss: 0.0307 - accuracy: 0.6500 - val_loss: 0.0834 - val_accuracy: 0.5172\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0491 - accuracy: 0.6333 - val_loss: 0.1865 - val_accuracy: 0.5172\n",
            "Epoch 93/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2200 - accuracy: 0.5000 - val_loss: 0.4456 - val_accuracy: 0.3448\n",
            "Epoch 94/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1462 - accuracy: 0.5667 - val_loss: 0.1000 - val_accuracy: 0.5862\n",
            "Epoch 95/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0193 - accuracy: 0.6500 - val_loss: 0.1325 - val_accuracy: 0.5172\n",
            "Epoch 96/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2257 - accuracy: 0.4500 - val_loss: 0.0786 - val_accuracy: 0.6207\n",
            "Epoch 97/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0591 - accuracy: 0.6333 - val_loss: 0.3937 - val_accuracy: 0.3793\n",
            "Epoch 98/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1961 - accuracy: 0.4667 - val_loss: 0.0641 - val_accuracy: 0.6207\n",
            "Epoch 99/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2134 - accuracy: 0.5833 - val_loss: 0.0746 - val_accuracy: 0.5517\n",
            "Epoch 100/100\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0160 - accuracy: 0.6500 - val_loss: 0.0762 - val_accuracy: 0.5172\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa8b04547f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 248
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yh-6p2xDtrUU"
      },
      "source": [
        "## Evaluación del modelo entrenado:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmOxSwezwXBY"
      },
      "source": [
        "### Prediciendo una imágen de prueba random"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kju4WmXuwXBY",
        "outputId": "4f308178-f887-4ae7-8e5b-235e39d88f94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        }
      },
      "source": [
        "import glob\n",
        "import random\n",
        "\n",
        "file_list = glob.glob(test_folder + '/**/**.jpg')\n",
        "img_path = random.choice(file_list)\n",
        "img_cat = os.path.split(os.path.dirname(img_path))[1]\n",
        "img = Image.open(img_path)\n",
        "X = np.array(img)\n",
        "\n",
        "REVERSED_IMAGE_CLASSES_MAP = dict(map(reversed, IMAGE_CLASSES_MAP.items()))\n",
        "\n",
        "def index_from_raw_prediction(prediction):\n",
        "    return min(round(prediction[0]), len(IMAGE_CLASSES) - 1)\n",
        "\n",
        "def result_from_raw_prediction(prediction):\n",
        "    return REVERSED_IMAGE_CLASSES_MAP[index_from_raw_prediction(prediction)]\n",
        "    \n",
        "print(\"Categories: \", REVERSED_IMAGE_CLASSES_MAP, \"\\n\")\n",
        "\n",
        "result = model.predict(process_images_array([X]))[0]\n",
        "\n",
        "print(\"Raw prediction: \", result)\n",
        "print(\"Prediction: \", result_from_raw_prediction(result))\n",
        "print(\"Actual Category: \", img_cat)\n",
        "\n",
        "plt.imshow(img)\n",
        "plt.axis('off')"
      ],
      "execution_count": 249,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Categories:  {0: 'bidon_plastico', 1: 'botella_normal', 2: 'bidon_retornable'} \n",
            "\n",
            "Raw prediction:  [0.8964462]\n",
            "Prediction:  botella_normal\n",
            "Actual Category:  botella_normal\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-0.5, 63.5, 63.5, -0.5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 249
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P55ueBtyIszz",
        "outputId": "1054123d-b995-4641-ee20-fa2f9ff5f5a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        }
      },
      "source": [
        "print(\"Configuración de RNA MLP Backpropagation definida: [\", num_inputs, hidden_layers_neuron_counts, num_outputs,\" ] \")\n",
        "print(\"Cantidad de iteraciones \", epochs_count)\n",
        "\n",
        " # evalua al modelo entrenado\n",
        "loss, accuracy = model.evaluate(_x_test, _y_test)\n",
        "print(\"\\n> Evaluación del Modelo: \")\n",
        "print(\"    - Error: \", loss * 100, \"%\")\n",
        "print(\"    - Exactitud: \", accuracy * 100,\"%\")\n",
        "print(\"\\n\")\n",
        "\n",
        "# procesa las imágenes con el modelo \n",
        "raw_predictions = model.predict(_x_test)\n",
        "\n",
        "predictions = list(map(result_from_raw_prediction, raw_predictions))\n",
        "actual_classes = list(map(lambda y: REVERSED_IMAGE_CLASSES_MAP[y], _y_test))\n",
        "\n",
        "# muestra reporte de clasificación\n",
        "print(\"\\nReporte de Clasificación: \")\n",
        "print(classification_report(actual_classes, predictions))\n",
        "\n",
        "# muestra matriz de confusion\n",
        "print('\\nMatriz de Confusión: ')\n",
        "cm = confusion_matrix(actual_classes, predictions, labels=IMAGE_CLASSES)\n",
        "print(pd.DataFrame(\n",
        "    cm, \n",
        "    index=['r:{:}'.format(x) for x in IMAGE_CLASSES], \n",
        "    columns=['p:{:}'.format(x) for x in IMAGE_CLASSES]\n",
        "  ))"
      ],
      "execution_count": 250,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Configuración de RNA MLP Backpropagation definida: [ 4096 [3000, 1024, 512] 1  ] \n",
            "Cantidad de iteraciones  100\n",
            "1/1 [==============================] - 0s 1ms/step - loss: 0.0406 - accuracy: 0.6562\n",
            "\n",
            "> Evaluación del Modelo: \n",
            "    - Error:  4.061754047870636 %\n",
            "    - Exactitud:  65.625 %\n",
            "\n",
            "\n",
            "\n",
            "Reporte de Clasificación: \n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "  bidon_plastico       1.00      1.00      1.00        10\n",
            "bidon_retornable       1.00      1.00      1.00        11\n",
            "  botella_normal       1.00      1.00      1.00        11\n",
            "\n",
            "        accuracy                           1.00        32\n",
            "       macro avg       1.00      1.00      1.00        32\n",
            "    weighted avg       1.00      1.00      1.00        32\n",
            "\n",
            "\n",
            "Matriz de Confusión: \n",
            "                    p:bidon_plastico  p:botella_normal  p:bidon_retornable\n",
            "r:bidon_plastico                  10                 0                   0\n",
            "r:botella_normal                   0                11                   0\n",
            "r:bidon_retornable                 0                 0                  11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlvySMHBwXBg"
      },
      "source": [
        "import glob\n",
        "import random\n",
        "\n",
        "file_list = glob.glob(test_folder + '/**/**.jpg')\n",
        "\n",
        "def index_from_raw_prediction(prediction):\n",
        "    return min(round(prediction[0]), len(IMAGE_CLASSES) - 1)\n",
        "\n",
        "def result_from_raw_prediction(prediction):\n",
        "    return REVERSED_IMAGE_CLASSES_MAP[index_from_raw_prediction(prediction)]\n",
        "\n",
        "for img_path in file_list:\n",
        "  img_cat = os.path.split(os.path.dirname(img_path))[1]\n",
        "  img = Image.open(img_path)\n",
        "  X = np.array(img)\n",
        "\n",
        "  REVERSED_IMAGE_CLASSES_MAP = dict(map(reversed, IMAGE_CLASSES_MAP.items()))\n",
        "\n",
        "  result = model.predict(process_images_array([X]))[0]\n",
        "\n",
        "  if result_from_raw_prediction(result) != img_cat:\n",
        "    print(\"Raw prediction: \", result)\n",
        "    print(\"Prediction: \", result_from_raw_prediction(result))\n",
        "    print(\"Actual Category: \", img_cat)\n",
        "\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')"
      ],
      "execution_count": 251,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKYgsFf9a2af"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "\n",
        "# directorio local en Google Drive\n",
        "path = 'gdrive/My Drive/IA/Modelo/model.h5'\n",
        "model.save(path,save_format='h5')"
      ],
      "execution_count": 252,
      "outputs": []
    }
  ]
}
